{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkkQNV+qv8Psrb9U0+MDhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/llm/blob/main/04DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "id": "AFl9JbnugW2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlW5DluKgBTZ",
        "outputId": "8459956c-6088-48a9-f6ef-0f348bb36cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('I', 'This'), ('love', 'is'), ('PyTorch', 'bad')], tensor([1, 0])]\n"
          ]
        }
      ],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer=str.split):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenizer(self.texts[idx])\n",
        "        return tokens, self.labels[idx]\n",
        "\n",
        "\n",
        "texts = [\"I love PyTorch\", \"This is bad\"]\n",
        "labels = [1, 0]\n",
        "\n",
        "ds = TextDataset(texts, labels)\n",
        "loader = DataLoader(ds, batch_size=2, shuffle=True)\n",
        "\n",
        "for batch in loader:\n",
        "    print(batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "    \"Fame's a fickle friend, Harry.\",\n",
        "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
        "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
        "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
        "    \"You are awesome!\"\n",
        "]\n",
        "\n",
        "# Define a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentences[idx]\n",
        "\n",
        "# Create an instance of your custom dataset\n",
        "custom_dataset = CustomDataset(sentences)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 2\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for batch in dataloader:\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7onyVV2gU5S",
        "outputId": "1681e9eb-abd2-49ae-e1ae-85e83c56232f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\", \"Fame's a fickle friend, Harry.\"]\n",
            "['Soon we must all face the choice between what is right and what is easy.', 'It is our choices, Harry, that show what we truly are, far more than our abilities.']\n",
            "['You are awesome!', 'Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext.transforms import BasicEnglishNormalize\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "sentences = [\n",
        "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "    \"Fame's a fickle friend, Harry.\",\n",
        "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
        "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
        "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
        "    \"You are awesome!\"\n",
        "]\n",
        "\n",
        "# ---- FIX 1: Modern tokenizer ----\n",
        "tokenizer = BasicEnglishNormalize()\n",
        "\n",
        "# ---- FIX 2: Build vocabulary ----\n",
        "def yield_tokens(data):\n",
        "    for text in data:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(sentences), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# ---- FIX 3: Dataset using new tokenizer ----\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences, tokenizer, vocab):\n",
        "        self.sentences = sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenizer(self.sentences[idx])\n",
        "        tensor_indices = torch.tensor([self.vocab[token] for token in tokens])\n",
        "        return tensor_indices\n",
        "\n",
        "# Create dataset\n",
        "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
        "\n",
        "print(\"Custom Dataset Length:\", len(custom_dataset))\n",
        "\n",
        "# Display items\n",
        "for i in range(len(custom_dataset)):\n",
        "    print(f\"Item {i+1}: {custom_dataset[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "H906ajNIgg0i",
        "outputId": "361b78ff-a0ed-4b3c-ab29-c9292bc592d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3765997864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasicEnglishNormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}