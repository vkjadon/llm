{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuTfTh+f06aHoq7PsZhrqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/llm/blob/main/hf_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `AutoModel` class from the `transformers` library to download and cache the specific model architecture and weights using `from_pretrained()` method. The AutoModel class is a wrappers designed to fetch the appropriate model architecture for a given checkpoint."
      ],
      "metadata": {
        "id": "hyVx3t6KKeaC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_p5zEIH3WSZ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case AutoModel will fetch a BERT model on the basis of the checkpoint provided in the `from_pretrained()` method. It downloads and chches the model architechure (12 layers, 768 hidden size, 12 attention heads) and the weights from HuggingFace Hub.\n",
        "\n",
        "However, we can use a specific model class directly in case we know the type of model we want to use for the checkpoint."
      ],
      "metadata": {
        "id": "fWv94u1HLMrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "4ba5MPxS3gwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and saving\n",
        "\n",
        "We can use `save_pretrained()` method, to save the model's weights and architecture configuration."
      ],
      "metadata": {
        "id": "RgJcGsHuNj1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"bert\")"
      ],
      "metadata": {
        "id": "eFDR2yUP6hDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will save two file in the path provided in the `save_pretrained()`. The path will have two files `config.json` and `model.safetensors`."
      ],
      "metadata": {
        "id": "JZ3EPrP8OG3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The config.json file have necessary attributes needed to build the model architecture and some metadata. The `model.safetensors` is the state dictionary containing weights.\n",
        "\n",
        "To reuse a saved model, use the from_pretrained() method again."
      ],
      "metadata": {
        "id": "lNkJWnrFO2WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert\")"
      ],
      "metadata": {
        "id": "G9KatFwq66jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Flow\n",
        "\n",
        "Transformer models handle text by turning the inputs into numbers. Here we will look at exactly what happens when your text is processed by the tokenizer."
      ],
      "metadata": {
        "id": "B6FsDSFJfwkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "XVpEvAGt7R8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can decode the input IDs to get back the original text"
      ],
      "metadata": {
        "id": "cwc0FZudgIzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "metadata": {
        "id": "hEOmtv4H7T1j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0e11c65-2011-4614-afd3-ca08551c8745"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] Hello, I ' m a single sentence! [SEP]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll notice that the tokenizer has added special tokens — [CLS] and [SEP] — required by the model. Not all models need special tokens; they’re utilized when a model was pretrained with them"
      ],
      "metadata": {
        "id": "mjPXxeOcgVcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "bYfdrsUV7aud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\", return_tensors=\"pt\")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "Jyx3lDJf7exV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\n",
        "    [\"How are you?\", \"I'm fine, thank you!\"], padding=True, return_tensors=\"pt\"\n",
        ")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "obfHmlxn7nui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\n",
        "    \"This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long sentence.\",\n",
        "    truncation=True,\n",
        ")\n",
        "print(encoded_input[\"input_ids\"])"
      ],
      "metadata": {
        "id": "XZnooR-u7rnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\n",
        "    [\"How are you?\", \"I'm fine, thank you!\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=5,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "WXssXZ7B7s_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\"How are you?\")\n",
        "print(encoded_input[\"input_ids\"])\n",
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "metadata": {
        "id": "bD3-e83D7xQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]"
      ],
      "metadata": {
        "id": "1lJX8q9f7ybf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}